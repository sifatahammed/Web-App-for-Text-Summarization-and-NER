{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qXRFmFoqvz7s"},"outputs":[],"source":["!pip install fastapi uvicorn nest-asyncio pyngrok transformers pdfminer.six PyPDF2\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtnTlifGQIHh","executionInfo":{"status":"ok","timestamp":1737420437984,"user_tz":-360,"elapsed":1740,"user":{"displayName":"Finding Middle Ground","userId":"08277277357871234255"}},"outputId":"2247cf4f-bd58-4cab-c520-6bccdf12a1b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.2)\n"]}],"source":["!pip install safetensors\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ILK6ITAA-cn"},"outputs":[],"source":["!pip install python-multipart\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lP8heIKr9vxF","executionInfo":{"status":"ok","timestamp":1737420468171,"user_tz":-360,"elapsed":26783,"user":{"displayName":"Finding Middle Ground","userId":"08277277357871234255"}},"outputId":"a37e5db0-f17c-41d3-9c68-4a9627728d81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from fastapi import FastAPI, UploadFile, File, HTTPException\n","from PyPDF2 import PdfReader\n","from fastapi.middleware.cors import CORSMiddleware\n","from pydantic import BaseModel\n","from transformers import (\n","    pipeline,\n","    AutoTokenizer,\n","    TFAutoModelForSeq2SeqLM,\n","    AutoModelForTokenClassification,\n",")\n","import uvicorn\n","import nest_asyncio\n","from pdfminer.high_level import extract_text\n","import csv\n","from pyngrok import ngrok\n","\n"],"metadata":{"id":"nFpYhRq4VsG0","executionInfo":{"status":"ok","timestamp":1737423122886,"user_tz":-360,"elapsed":3,"user":{"displayName":"Finding Middle Ground","userId":"08277277357871234255"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sN-Y6kjUDrpy","executionInfo":{"status":"ok","timestamp":1737424480456,"user_tz":-360,"elapsed":1028,"user":{"displayName":"Finding Middle Ground","userId":"08277277357871234255"}},"outputId":"32097b39-4e64-400c-94c4-c3a8b6ba7905"},"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","Public URL: https://6e7b-35-233-177-138.ngrok-free.app\n"]}],"source":["!ngrok authtoken ***********\n","ngrok_tunnel = ngrok.connect(8000)\n","print(f\"Public URL: {ngrok_tunnel.public_url}\")\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"k3KBm07Lv6os","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737424649826,"user_tz":-360,"elapsed":162374,"user":{"displayName":"Finding Middle Ground","userId":"08277277357871234255"}},"outputId":"9d57c88e-ed3b-4fd2-84a8-622291f3aa3b"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:asyncio:Task exception was never retrieved\n","future: <Task finished name='Task-46' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 579, in run\n","    server.run()\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n","    return asyncio.run(self.serve(sockets=sockets))\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n","    return loop.run_until_complete(task)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n","    self._run_once()\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n","    self.__step()\n","  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n","    result = coro.send(None)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n","    with self.capture_signals():\n","  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n","    next(self.gen)\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n","    signal.raise_signal(captured_signal)\n","KeyboardInterrupt\n","ERROR:asyncio:Task exception was never retrieved\n","future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 579, in run\n","    server.run()\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n","    return asyncio.run(self.serve(sockets=sockets))\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n","    return loop.run_until_complete(task)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n","    self._run_once()\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n","    self.__step()\n","  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n","    result = coro.send(None)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n","    with self.capture_signals():\n","  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n","    next(self.gen)\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n","    signal.raise_signal(captured_signal)\n","KeyboardInterrupt\n","ERROR:asyncio:Task exception was never retrieved\n","future: <Task finished name='Task-28' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 579, in run\n","    server.run()\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n","    return asyncio.run(self.serve(sockets=sockets))\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n","    return loop.run_until_complete(task)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n","    self._run_once()\n","  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n","    self.__step()\n","  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n","    result = coro.send(None)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n","    with self.capture_signals():\n","  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n","    next(self.gen)\n","  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n","    signal.raise_signal(captured_signal)\n","KeyboardInterrupt\n","All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n","\n","All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/text_summarization.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n","Device set to use 0\n","Device set to use cuda:0\n","INFO:     Started server process [629]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:     27.147.190.196:0 - \"OPTIONS /summarization HTTP/1.1\" 200 OK\n","INFO:     27.147.190.196:0 - \"POST /summarization HTTP/1.1\" 200 OK\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [629]\n"]}],"source":["\n","# Initialize FastAPI\n","app = FastAPI()\n","\n","# Allow CORS for frontend communication\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=[\"*\"],\n","    allow_credentials=True,\n","    allow_methods=[\"*\"],\n","    allow_headers=[\"*\"],\n",")\n","\n","# Paths to saved models and tokenizer directories\n","summarization_model_path = \"/content/drive/MyDrive/text_summarization\"\n","summarization_tokenizer_path = \"/content/drive/MyDrive/text_summariztion_tf\"\n","ner_model_path = \"/content/drive/MyDrive/NER/Model/NER\"\n","ner_tokenizer_path = \"/content/drive/MyDrive/NER/Model/NER_tf\"\n","\n","# Load models and tokenizers\n","# Text Summarization (TensorFlow)\n","summarization_tokenizer = AutoTokenizer.from_pretrained(summarization_tokenizer_path)\n","summarization_model = TFAutoModelForSeq2SeqLM.from_pretrained(summarization_model_path)\n","summarization_pipeline = pipeline(\n","    \"summarization\",\n","    model=summarization_model,\n","    tokenizer=summarization_tokenizer,\n","    framework=\"tf\",\n",")\n","\n","# Named Entity Recognition (PyTorch)\n","ner_tokenizer = AutoTokenizer.from_pretrained(ner_tokenizer_path)\n","ner_model = AutoModelForTokenClassification.from_pretrained(ner_model_path)\n","ner_pipeline = pipeline(\n","    \"ner\",\n","    model=ner_model,\n","    tokenizer=ner_tokenizer,\n","    aggregation_strategy=\"simple\"\n",")\n","\n","# API Models\n","class TextRequest(BaseModel):\n","    text: str\n","\n","\n","# Root endpoint\n","@app.get(\"/\")\n","def root():\n","    return {\"message\": \"Backend is running!\"}\n","\n","# Summarization endpoint\n","@app.post(\"/summarization\")\n","def summarize_text(request: TextRequest):\n","    try:\n","        summary = summarization_pipeline(request.text, max_length=130, min_length=70, do_sample=False)\n","        return {\"summary\": summary[0][\"summary_text\"]}\n","    except Exception as e:\n","        raise HTTPException(status_code=500, detail=f\"Error during summarization: {str(e)}\")\n","\n","# NER endpoint\n","@app.post(\"/ner\")\n","def ner_text(request: TextRequest):\n","    try:\n","        # Tokenize input\n","        inputs = ner_tokenizer(\n","            request.text,\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            padding=True,\n","            max_length=128\n","        )\n","\n","        # Perform inference\n","        outputs = ner_model(**inputs)\n","        predictions = outputs.logits.argmax(-1)\n","\n","        # Convert predictions to labels\n","        tokens = ner_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze())\n","        label_map = {\n","                    0: \"O\",         # Outside of an entity\n","                    1: \"B-PER\",     # Beginning of a person's name\n","                    2: \"I-PER\",     # Inside a person's name\n","                    3: \"B-LOC\",     # Beginning of a location\n","                    4: \"I-LOC\",     # Inside a location\n","                    5: \"B-ORG\",     # Beginning of an organization\n","                    6: \"I-ORG\",     # Inside an organization\n","                    7: \"B-MISC\",    # Beginning of a miscellaneous entity\n","                    8: \"I-MISC\",    # Inside a miscellaneous entity\n","                }\n","        predicted_labels = [label_map[label] for label in predictions.squeeze().tolist()]\n","        tokens = [token.replace(\"‚ñÅ\", \"\") for token in tokens]\n","\n","        # Filter out \"O\" labels\n","        filtered_results = [\n","            (token, label)\n","            for token, label in zip(tokens, predicted_labels)\n","            if label != \"O\"\n","        ]\n","        for token, label in filtered_results:\n","          print(f\"{token}: {label}\")\n","        return {\"entities\": filtered_results}\n","    except Exception as e:\n","        raise HTTPException(status_code=500, detail=f\"Error during NER: {str(e)}\")\n","\n","\n","# File upload endpoint (supports .txt and .pdf)\n","@app.post(\"/upload\")\n","async def upload_file(file: UploadFile = File(...)):\n","    try:\n","        if file.filename.endswith(\".txt\"):\n","            content = await file.read()\n","            text = content.decode(\"utf-8\")\n","        elif file.filename.endswith(\".pdf\"):\n","            pdf_reader = PdfReader(file.file)\n","            text = \"\"\n","            for page in pdf_reader.pages:\n","                text += page.extract_text()\n","        else:\n","            raise HTTPException(status_code=400, detail=\"Unsupported file format\")\n","        return {\"text\": text}\n","    except Exception as e:\n","        raise HTTPException(status_code=500, detail=f\"Error processing file: {str(e)}\")\n","\n","# Health check endpoint for testing the backend\n","@app.get(\"/health\")\n","def health_check():\n","    return {\"status\": \"Healthy!\"}\n","\n","nest_asyncio.apply()\n","uvicorn.run(app, host=\"0.0.0.0\", port=8000)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMWu6BMtvNdrWeVJAx2nI7S"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}